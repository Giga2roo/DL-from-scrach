{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3. 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 퍼셉트론에서 신경망으로\n",
    "- 신경망 vs. 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 신경망의 예\n",
    "- 구성: 입력층(Input layer) - 은닉층(Hidden layer) - 출력층(Output layer)\n",
    "- `은닉층`의 뉴런은 사람 눈에 보이지 않음\n",
    "- `가중치`를 가지는 층은 0층(입력층), 1층(은닉층) $rightarrow$ `2층 신경망`이라 부를 수 있음 (문헌에 따라 다를 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 퍼셉트론 복습\n",
    "- ${x_1, x_2}$: 입력 신호\n",
    "- ${y}$: 출력 신호\n",
    "- $b$: `편향`을 나타내는 매개변수, 뉴런이 얼마나 쉽게 활성화되느냐를 제어 \n",
    "- ${w_1, w_2}$: 가중치(weight), 각 신호의 영향력을 제어\n",
    "- 뉴런에서 보내온 신호의 총합이 정해진 한계(${\\theta}$,Threshold, 임계값)을 넘어설 때만 1을 출력\n",
    "\n",
    "$${y =\\begin{cases}0 \\ (b \\ + \\ w_1x_1 \\ + \\ w_2x_2 \\ \\leq \\ \\theta) \\\\ 1 \\ (b \\ + \\ w_1x_1 \\ + \\ w_2x_2 \\ > \\ \\theta )\\end{cases}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 식을 더 간결하게 바꿔보자\n",
    "- 조건 분기의 동작(0을 넘으면 1을 출력하고 그렇지 않으면 0을 출력)\n",
    "- 이 함수를 $h(x)$라면 위 식을 아래와 같이 표현할 수 있음\n",
    "\n",
    "$$y = h(b + w_1x_1 + w_2x_2)$$\n",
    "- 입력 신호의 총합이 $h(x)$라는 함수를 거쳐 변환, 그 변환된 값이 $y$의 출력이 됨을 표현\n",
    "</br></br>\n",
    "$${h(x) =\\begin{cases}0 \\ (x \\ \\leq \\ 0) \\\\ 1 \\ (x \\ > \\ 0)\\end{cases}}$$\n",
    "- $h(x)$ 함수는 입력이 0을 넘으면 1을 돌려주고, 그렇지 않으면 0을 돌려줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 활성화 함수의 등장\n",
    "- $h(x)$: 입력 신호의 총합을 출력 신호로 변환하는 함수 `활성화 함수(Activate function)`\n",
    "- 수식 표현\n",
    "$$a = b + w_1x_1 + w_2x_2$$ \n",
    "$$ y = h(a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가중치가 달린 입력 신호와 편향의 총합을 계산하여 이를 $a$라고 함\n",
    "- a를 함수에 $h()$에 넣어 $y$를 출력₩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 활성화 함수\n",
    "- 계단 함수(step function): 임계값을 경계로 출력이 바뀌는 활성화 함수(activate function)\n",
    "    + `perceptron`에서는 활성화 함수로 `계단 함수`를 이용한다고 할 수 있음.\n",
    "    <br/><br/>\n",
    "- `활성화 함수`를 계단 함수에서 다른 함수로 변경하는 것이 신경망의 세계로 나아가는 열쇠!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Sigmoid 함수\n",
    "$$ h(x) = \\frac{1}{1 + exp(-x)}$$\n",
    "- $exp(x)$는 $e^{-x}$를 뜻함 ($e$는 자연상수로 2.7182...의 값을 가지는 실수)\n",
    "- 신경망에서는 활성화 함수로 시그모이드 함수를 이용해 `신호를 변환` $rightarrow$ 변환된 신호를 다음 뉴런에 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 계단 함수 구현하기\n",
    "- 계딴 함수는 입력이 0을 넘으면 1을 출력하고, 그 외에는 0을 출력하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인수 $x$는 실수(부동소수점)만 받아들임\n",
    "- `numpy 배열을 지원`하도록 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
